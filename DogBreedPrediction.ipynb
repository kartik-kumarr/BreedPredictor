{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kartik-kumarr/BreedPredictor/blob/main/DogBreedPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n"
      ],
      "metadata": {
        "id": "dM61uBtHvpF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "\n",
        "file_id = '1y_w4F99K2M8j-Mq1Gl2tl3wxG4z7SoQ9'\n",
        "\n",
        "gdown.download(f'https://drive.google.com/uc?export=download&id={file_id}', 'dog_dataset.zip', quiet=False)"
      ],
      "metadata": {
        "id": "EJMmGUAyvarf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/dog_dataset.zip -d /content/dogs/"
      ],
      "metadata": {
        "id": "OLk2K6dbkfuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "dogs_folder = '/content/dogs/'\n",
        "files_in_folder = os.listdir(dogs_folder)\n",
        "\n",
        "\n",
        "print(files_in_folder)"
      ],
      "metadata": {
        "id": "OtXhdWqvv4n-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = '/content/dogs/images/Images/'\n",
        "img_width, img_height = 224, 224\n",
        "channels = 3\n",
        "batch_size = 64\n",
        "num_images= 50\n",
        "image_arr_size= img_width * img_height * channels"
      ],
      "metadata": {
        "id": "32ws1oJOwx0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from skimage.transform import resize\n",
        "from IPython.display import SVG\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.utils import to_categorical, model_to_dot, plot_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "Z-xDIyE2x1xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_images(image_dir):\n",
        "\n",
        "    image_index = 0\n",
        "    image_arr_size= img_width * img_height * channels\n",
        "    images = np.ndarray(shape=(num_images, image_arr_size))\n",
        "    labels = np.array([])\n",
        "\n",
        "    for type in os.listdir(image_dir)[:50]:\n",
        "        type_images = os.listdir(image_dir + type)\n",
        "        labels= np.append(labels, type.split('-')[1])\n",
        "\n",
        "        for image in type_images[:1]:\n",
        "            image_file = os.path.join(image_dir, type + '/', image)\n",
        "            image_data = mpimg.imread(image_file)\n",
        "            image_resized = resize(image_data, (img_width, img_height), anti_aliasing=True)\n",
        "            images[image_index, :] = image_resized.flatten()\n",
        "            print (type, ':', image)\n",
        "            image_index += 1\n",
        "\n",
        "    return (images, labels)\n",
        "\n",
        "def plot_images(instances, images_per_row=10, **options):\n",
        "    size = img_width\n",
        "    images_per_row = min(len(instances), images_per_row)\n",
        "    images = [instance.reshape(img_width, img_height, channels) for instance in instances]\n",
        "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
        "    row_images = []\n",
        "    n_empty = n_rows * images_per_row - len(instances)\n",
        "    images.append(np.zeros((img_width, img_height * n_empty)))\n",
        "    for row in range(n_rows):\n",
        "        if (row == len(instances)/images_per_row):\n",
        "            break\n",
        "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
        "        row_images.append(np.concatenate(rimages, axis=1))\n",
        "    image = np.concatenate(row_images, axis=0)\n",
        "    plt.figure(figsize=(20,20))\n",
        "    plt.imshow(image, **options)\n",
        "    plt.axis(\"off\")\n",
        "    plt.savefig('dogs_images.png', transparent= True, bbox_inches= 'tight', dpi= 900)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xxWtEQQvxAt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = get_images(train_data_dir)\n",
        "plot_images(images)"
      ],
      "metadata": {
        "id": "AtWSHd0axzH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    shear_range= 0.2,\n",
        "    zoom_range= 0.2,\n",
        "    horizontal_flip= True,\n",
        "    rotation_range= 20,\n",
        "    width_shift_range= 0.2,\n",
        "    height_shift_range= 0.2,\n",
        "    validation_split=0.2,\n",
        "\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    validation_split=0.2,\n",
        ")"
      ],
      "metadata": {
        "id": "KLLK4SnUx75k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size= (img_width, img_height),\n",
        "    color_mode= 'rgb',\n",
        "    batch_size= batch_size,\n",
        "    class_mode= 'categorical',\n",
        "    subset='training',\n",
        "    shuffle= True,\n",
        "    seed= 1337\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size= (img_width, img_height),\n",
        "    color_mode= 'rgb',\n",
        "    batch_size= batch_size,\n",
        "    class_mode= 'categorical',\n",
        "    subset='validation',\n",
        "    shuffle= True,\n",
        "    seed= 1337\n",
        ")"
      ],
      "metadata": {
        "id": "4MJOvLiuydSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num_classes = len(train_generator.class_indices)\n",
        "# train_labels = train_generator.classes\n",
        "# train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "# valid_labels = valid_generator.classes\n",
        "# valid_labels = to_categorical(valid_labels, num_classes=num_classes)\n",
        "# nb_train_samples = len(train_generator.filenames)\n",
        "# nb_valid_samples = len(valid_generator.filenames)"
      ],
      "metadata": {
        "id": "y_kuFVzsyd5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "# from tensorflow.keras.applications import InceptionV3\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# # Define the image dimensions (replace img_width and img_height with actual values)\n",
        "# img_width = 224  # Example: Replace with your image width\n",
        "# img_height = 224  # Example: Replace with your image height\n",
        "# num_classes = 120  # Replace with your actual number of classes (dog breeds)\n",
        "# batch_size = 32  # Define your batch size\n",
        "\n",
        "\n",
        "# # Load InceptionV3 as the base model, without the top layers (classification head)\n",
        "# base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "# # Freeze the base model layers (you can fine-tune later if needed)\n",
        "# base_model.trainable = False\n",
        "\n",
        "# # Add custom layers on top of InceptionV3\n",
        "# x = base_model.output\n",
        "# x = GlobalAveragePooling2D()(x)\n",
        "# x = Dense(1024, activation='relu')(x)\n",
        "# x = Dropout(0.5)(x)\n",
        "# x = Dense(512, activation='relu')(x)\n",
        "# x = Dropout(0.5)(x)\n",
        "# x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# # Create the final model\n",
        "# model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Print model summary\n",
        "# model.summary()\n",
        "\n",
        "# # Data augmentation and image preprocessing\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#     rescale=1./255,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True,\n",
        "#     rotation_range=20,\n",
        "#     width_shift_range=0.2,\n",
        "#     height_shift_range=0.2,\n",
        "#     validation_split=0.2\n",
        "# )\n",
        "\n",
        "# valid_datagen = ImageDataGenerator(\n",
        "#     rescale=1./255,\n",
        "#     validation_split=0.2\n",
        "# )\n",
        "\n",
        "# # Training data generator\n",
        "# train_generator = train_datagen.flow_from_directory(\n",
        "#     train_data_dir,\n",
        "#     target_size=(img_width, img_height),\n",
        "#     color_mode='rgb',\n",
        "#     batch_size=batch_size,\n",
        "#     class_mode='categorical',\n",
        "#     subset='training',\n",
        "#     shuffle=True,\n",
        "#     seed=1337\n",
        "# )\n",
        "\n",
        "# # Validation data generator\n",
        "# valid_generator = valid_datagen.flow_from_directory(\n",
        "#     train_data_dir,\n",
        "#     target_size=(img_width, img_height),\n",
        "#     color_mode='rgb',\n",
        "#     batch_size=batch_size,\n",
        "#     class_mode='categorical',\n",
        "#     subset='validation',\n",
        "#     shuffle=True,\n",
        "#     seed=1337\n",
        "# )\n",
        "\n",
        "# # Train the model\n",
        "# history = model.fit(\n",
        "#     train_generator,\n",
        "#     steps_per_epoch=len(train_generator),\n",
        "#     epochs=22,\n",
        "#     validation_data=valid_generator,\n",
        "#     validation_steps=len(valid_generator),\n",
        "# )\n",
        "\n",
        "# # Evaluate the model on the validation data\n",
        "# score = model.evaluate(valid_generator, verbose=1)\n",
        "# print(\"Validation Loss:\", score[0])\n",
        "# print(\"Validation Accuracy:\", score[1])"
      ],
      "metadata": {
        "id": "4UksMDN_ymZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Plot training & validation accuracy values\n",
        "# plt.figure(figsize=(12, 4))\n",
        "\n",
        "# plt.subplot(1, 2, 1)\n",
        "# plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "# plt.title('Training and Validation Accuracy')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.legend()\n",
        "\n",
        "# # Plot training & validation loss values\n",
        "# plt.subplot(1, 2, 2)\n",
        "# plt.plot(history.history['loss'], label='Training Loss')\n",
        "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "# plt.title('Training and Validation Loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "jdf7L-Liy8PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Save the model weights\n",
        "# model.save_weights('/content/dogsModel.weights.h5')"
      ],
      "metadata": {
        "id": "EiRZDvL6zCIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!gdown --id 1ktXYuNoNngaWuyEtdjh5Vu5_iUbPStbX -O /content/dogsModel.weights.h5\n",
        "\n",
        "print(\"Downloaded files:\", os.listdir(\"/content/\"))\n"
      ],
      "metadata": {
        "id": "Xb5snHGh3etI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import files\n",
        "import time\n",
        "from termcolor import colored\n",
        "\n",
        "img_width, img_height = 224, 224\n",
        "num_classes = 120\n",
        "\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "model.load_weights('/content/dogsModel.weights.h5')\n",
        "\n",
        "def predict_dog_breed(image_path, model):\n",
        "    img = image.load_img(image_path, target_size=(img_width, img_height))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
        "    class_labels = list(train_generator.class_indices.keys())\n",
        "    predicted_breed = class_labels[predicted_class]\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicted Breed: {predicted_breed}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    return predicted_breed\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    image_path = list(uploaded.keys())[0]\n",
        "    print(colored(\"\\n🎉🎂 Happy Birthday to Grapes(🍇) and Ting! 🎂🎉\\n\", \"magenta\", attrs=[\"bold\"]))\n",
        "    print(colored(\"✨ Let's see which majestic breed your beloved dog is! ✨\\n\", \"cyan\", attrs=[\"bold\"]))\n",
        "\n",
        "    time.sleep(1)\n",
        "    print(colored(f\"📸 Uploading image: {image_path} ...\", \"yellow\"))\n",
        "    time.sleep(1)\n",
        "\n",
        "    predicted_breed = predict_dog_breed(image_path, model)\n",
        "\n",
        "    print(colored(\"\\n🐶 Drumroll please... 🥁🥁🥁\\n\", \"blue\", attrs=[\"bold\"]))\n",
        "    time.sleep(2)\n",
        "    print(colored(f\"🎊 The predicted breed is: {predicted_breed} 🎊\", \"green\", attrs=[\"bold\", \"underline\"]))\n",
        "\n",
        "    print(colored(\"\\n Wishing you and Grapes the best day ever!\", \"red\", attrs=[\"bold\"]))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "score = model.evaluate(valid_generator, verbose=0)\n",
        "print(f\"Result is {score[1] * 100:.2f}% accurate.\")"
      ],
      "metadata": {
        "id": "GdYdzZ4byCKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GxSuxmsi1UeH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}